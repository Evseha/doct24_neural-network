Применение методов Data Science и анализа данных в медицине для предсказания заболеваемости диабетом
Харченко Евгений

2023-06-08
В данной статье я исследую применение Data Science и методов анализа данных с применением машинного обучения в медицине для предсказания заболеваемости диабетом на основе 253680 ответов американских граждан на опрос CDC BRFSS 2015 (Система наблюдения за поведенческими факторами риска (BRFSS) - это телефонный опрос, связанный со здоровьем, который ежегодно собирается CDC). Мы рассмотрим анализ данных, применяемые алгоритмы и модели машинного обучения, а также рассмотрим результаты каждой модели.
Введение
Введение в тему статьи, объяснение актуальности исследования С развитием технологий
Цель и задачи исследования
Основная цель исследования было выявления заболеваемости диабетом, а также выявления преддиабета с применением методов анализа данных и машинного обучения.
Методология
Построение предсказательных моделей было произведено с использованием Random Forest, Decision Tree, Cat Boost, LGBM, KNN. 
Медицинские данные
В качестве исходных данных был взят набор данных из открытых источников, содержащий обезличенные медицинские данные опроса, связанного со здоровьем, который ежегодно собирается CDC. Каждый год в ходе опроса собираются ответы более 400 000 американцев о рискованном поведении, связанных со здоровьем, хронических заболеваниях и использовании профилактических услуг. Он проводится ежегодно с 1984 года. Для этого проекта был использован CSV-файл набора данных, доступного на Kaggle за 2015 год. [https://www.kaggle.com/datasets/alexteboul/diabetes-health-indicators-dataset]
В качестве исходных данных рассматривались следующие показатели:
•	Diabetes_012 – целевой признак, показывающий наличие преддиабета, диабета или отсутствие вышеперечисленных;
•	HighBP – наличие высокого артериального давления;
•	HighChol – наличие высокого холестерина;
•	CholCheck – была ли проверка на холестерин за последние 5 лет;
•	BMI – индекс массы тела;
•	Smoker – выкурил ли ислледуемый 100 сигарет на протяжении всей жизни;
•	Stroke – был л и инсульт;
•	HeartDiseaseorAttack – был ли инфаркт;
•	PhysActivity – была ли физическая активность за последние 30 дней;
•	Fruits – употребление фруктов в течении дня;
•	Veggies – употребление овощей в течении дня;
•	HvyAlcoholConsump – употребление крепкого алкоголя;
•	GenHlth – 5 бальная шкала здоровья;
•	AnyHealthcare – наличие медицинской страховки;
•	NoDocbcCost – были ли случат, когда пропускали посещение врача;
•	MentHlth – психическое здоровье (наличие стрессов);
•	PhysHlth - физические болезни и травмы, в течение последних нескольких дней;
•	DiffWalk – затруднения при ходьбе;
•	Sex - пол;
•	Age - возрастная категория 13-го уровня (_AGEG5YR, смотрите кодовую книгу);
•	Income - Шкала доходов;

Моделирование и предсказание
Исходный набор данных содержит ответы от 441 455 человек.
Для определения степени влияния исходных параметров на результат были использованы 5 алгоритмов:
•	Random forest;
•	Decision Tree;
•	CatBoost;
•	LGBM;
•	KNN.

В исследуемых данных были только числовые признаки, обработки категориальных признаков не потребовалось. Каждая из предсказательных моделей получала целевую переменную, которую в дальнейшем должна была предсказать.
Каждый из используемых алгоритмов имеет свои особенности, преимущества и ограничения, которые могут варьироваться в зависимости от конкретной задачи и набора данных. 
Cat Boost показал следующий результат:
Best hyperparameter: {'learning_rate': 0.08503859825373385,  'l2_leaf_reg': 8.0, 'min_data_in_leaf': 100,  'depth': 5,  'grow_policy': 'Depthwise',  'bootstrap_type': 'Bernoulli',  'subsample': 0.6816771850580444}
Best cross-val score: 0.8535944962542519

Decision Tree показал следующий результат:
Best hyperparameter: { max_depth=5}
Best cross-val score: 0.79006316

Random Forest показал следующий результат:
Best hyperparameter: { random_state=12345, n_estimators=71, max_depth=5, lass_weight='balanced'}
Best cross-val score: 0.61221053

KNeighborsClassifier показал следующий результат:
Best hyperparameter: n_neighbors = 5}
Best cross-val score: 0.56078029
 
LGBM показал следующий результат:
Mean cross-val score: 0.587

Важность признаков по результатам обучения Cat Boost
Рассчитаем и визуализируем важность признаков (feature importance).
feature_importance = catboost.feature_importances_
sorted_idx = np.argsort(feature_importance)
fig = plt.figure(figsize=(12, 6))
plt.barh(range(len(sorted_idx)), feature_importance[sorted_idx], align='center')
plt.yticks(range(len(sorted_idx)), np.array(X_train.columns)[sorted_idx])
plt.title('Feature Importance');
 
Важность признаков в сочетании друг с другом
Функция feature_importances предоставляет информацию о важности каждого признака в модели, что помогает понять, какие признаки играют ключевую роль в принятии решений моделью.
Для получения результатов обучения модели мною был написан код, который принимал на вход модель, признаки и целевой признак, а выдавал показатели такие как Accuracy, F1, recall, precision и строил матрицу ошибок:
def checkstat (model, X_train, y_train): 
    model.fit(X_train, y_train)
    predicted_test=model.predict(X_test)
    print('Accuracy :', accuracy_score(y_test, predicted_test))
    print("F1:", f1_score(y_test, predicted_test, average='micro'))
    print('recall:', recall_score(y_test, predicted_test, average='micro'))
    print('precision:', precision_score(y_test, predicted_test, average='micro'))
    cm = confusion_matrix(y_test, predicted_test, labels=model.classes_)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm,
                               display_labels=model.classes_)
    disp.plot()
    plt.show() 
Матрица ошибок
Из визуального представления матрицы ошибок можно визуально оценить качество работы модели классификации и выявить типы ошибок, которые она делает при предсказаниях. 

Заключение
Затруднение в походке явный показатель наличия заболевания

