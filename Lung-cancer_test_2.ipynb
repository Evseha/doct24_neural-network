{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMu6G6Si/G5MXmH8S7k7oxK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Импорт библиотек TensorFlow"],"metadata":{"id":"vSZxF10Qf_n0"}},{"cell_type":"code","source":["!pip install pydicom"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NuHrkulNgFHO","executionInfo":{"status":"ok","timestamp":1675346231461,"user_tz":-180,"elapsed":8392,"user":{"displayName":"Илья Андреевич","userId":"13920647134536331916"}},"outputId":"fb77b019-933c-4cdc-db6e-e737f73852eb"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pydicom\n","  Downloading pydicom-2.3.1-py3-none-any.whl (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pydicom\n","Successfully installed pydicom-2.3.1\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import os\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n","import time\n","import matplotlib.pyplot as plt\n","import cv2\n","import seaborn as sns\n","sns.set_style('darkgrid')\n","import shutil\n","import pydicom as dicom\n","\n","from sklearn.metrics import confusion_matrix, classification_report\n","from sklearn.model_selection import train_test_split\n","from skimage.transform import resize\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n","from tensorflow.keras.layers import Dense, Activation,Dropout,Conv2D, MaxPooling2D,BatchNormalization\n","from tensorflow.keras.optimizers import Adam, Adamax\n","from tensorflow.keras.metrics import categorical_crossentropy\n","from tensorflow.keras import regularizers\n","from tensorflow.keras.models import Model\n","from tensorflow.keras import backend as K\n","import time\n","from tqdm import tqdm\n","from sklearn.metrics import f1_score\n","import sys\n","if not sys.warnoptions:\n","    import warnings\n","    warnings.simplefilter(\"ignore\")\n","pd.set_option('display.max_columns', None)  # or 1000\n","pd.set_option('display.max_rows', None)  # or 1000\n","pd.set_option('display.max_colwidth', None)  # or 199\n","\n","print('All modules TensorFlow have been imported')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KE6bPITWf9V6","executionInfo":{"status":"ok","timestamp":1675346252145,"user_tz":-180,"elapsed":10236,"user":{"displayName":"Илья Андреевич","userId":"13920647134536331916"}},"outputId":"8acebf48-b9cb-447e-e3ef-882c73f6fed9"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["All modules TensorFlow have been imported\n"]}]},{"cell_type":"markdown","source":["Импорт библиотек PyTorch"],"metadata":{"id":"jdo6lZe_gSSp"}},{"cell_type":"code","source":["!pip install torchsummary torch-summary "],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":207},"id":"wWKeqq9ngYSV","executionInfo":{"status":"ok","timestamp":1675346319545,"user_tz":-180,"elapsed":4427,"user":{"displayName":"Илья Андреевич","userId":"13920647134536331916"}},"outputId":"380249d3-94af-4253-ddb8-9726ed59a8b3"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torchsummary in /usr/local/lib/python3.8/dist-packages (1.5.1)\n","Collecting torch-summary\n","  Downloading torch_summary-1.4.5-py3-none-any.whl (16 kB)\n","Installing collected packages: torch-summary\n","Successfully installed torch-summary-1.4.5\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["torchsummary"]}}},"metadata":{}}]},{"cell_type":"code","source":["import pickle\n","\n","from os import listdir\n","from os.path import isfile, join\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.autograd import Variable\n","from torch.utils.data import Dataset\n","from torchvision import datasets, models, transforms\n","from torchvision.models import resnet18\n","\n","\n","from torchsummary import summary\n","\n","import gc\n","gc.collect()\n","\n","import cv2\n","\n","from sklearn.model_selection import train_test_split\n","\n","from tqdm import tqdm\n","from tqdm.auto import tqdm as tqdm_\n","from tqdm.notebook import tqdm as tqdm_step\n","\n","from PIL import Image\n","\n","import matplotlib.pyplot as plt\n","from IPython.display import clear_output\n","\n","from graphviz import Digraph\n","\n","print('All modules PyTorch have been imported')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VdXyRM9ggYUx","executionInfo":{"status":"ok","timestamp":1675346315121,"user_tz":-180,"elapsed":3729,"user":{"displayName":"Илья Андреевич","userId":"13920647134536331916"}},"outputId":"222382eb-d5fe-4981-e70b-fec1d5d28583"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["All modules PyTorch have been imported\n"]}]},{"cell_type":"code","source":["class ASPPBlock(nn.Module):\n","    def __init__(self, channels):\n","        super().__init__()\n","        self.conv1 = torch.nn.Conv2d(kernel_size=(1, 1), in_channels=channels, out_channels=channels, padding=0)\n","        self.conv2 = torch.nn.Conv2d(kernel_size=(3, 3), in_channels=channels, out_channels=channels, padding=6, dilation=(6, 6))\n","        #self.conv3 = torch.nn.Conv2d(kernel_size=(3, 3), in_channels=channels, out_channels=channels, padding=12, dilation=(12,12))\n","        #self.conv4 = torch.nn.Conv2d(kernel_size=(3, 3), in_channels=channels, out_channels=channels, padding=18, dilation=(18,18))\n","        self.conv5 = torch.nn.Conv2d(kernel_size=(1, 1), in_channels=channels*2, out_channels=channels)\n","        \n","    def forward(self, inp):\n","        out1 = torch.nn.functional.relu(self.conv1(inp))\n","        #print(f\"out1\",np.shape(out1))\n","        out2 = torch.nn.functional.relu(self.conv2(inp))\n","        #print(f\"out2\",np.shape(out2))\n","        #out3 = torch.nn.functional.relu(self.conv3(inp))\n","        #print(f\"out3\",np.shape(out3))\n","        #out4 = torch.nn.functional.relu(self.conv4(inp))\n","        #print(f\"out4\",np.shape(out4))\n","        #out = torch.cat((out1, out2, out3, out4), dim=1)\n","        out = torch.cat((out1, out2), dim=1)\n","        #print(f\"out\",np.shape(out))\n","        out = torch.nn.functional.relu(self.conv5(out))\n","        return out"],"metadata":{"id":"b5NiWq0cgest","executionInfo":{"status":"ok","timestamp":1675347754123,"user_tz":-180,"elapsed":2,"user":{"displayName":"Илья Андреевич","userId":"13920647134536331916"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["class DownSampling(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size=3):\n","        super().__init__()\n","        self.conv1 = torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=out_channels, padding=1)\n","        self.bn2d1 = torch.nn.BatchNorm2d(out_channels)\n","        self.conv2 = torch.nn.Conv2d(kernel_size=kernel_size, in_channels=out_channels, out_channels=out_channels, padding=1)\n","        self.bn2d2 = torch.nn.BatchNorm2d(out_channels)\n","        \n","    def forward(self, inp):\n","        out = torch.nn.functional.relu(self.conv1(inp))\n","        out = self.bn2d1(out)\n","        out = torch.nn.functional.relu(self.conv2(out))\n","        out = self.bn2d2(out)\n","        return out"],"metadata":{"id":"YIeWKQRSgi3W","executionInfo":{"status":"ok","timestamp":1675347769921,"user_tz":-180,"elapsed":1,"user":{"displayName":"Илья Андреевич","userId":"13920647134536331916"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["class Bottlenack(nn.Module):\n","    def __init__(self, in_channels):\n","        super().__init__()\n","        self.conv1 = torch.nn.Conv2d(kernel_size=3, in_channels=in_channels, out_channels=in_channels*2, padding=1)\n","        self.bn2d1 = torch.nn.BatchNorm2d(in_channels*2)\n","        self.conv2 = torch.nn.Conv2d(kernel_size=3, in_channels=in_channels*2, out_channels=in_channels*2, padding=1)\n","        self.bn2d2 = torch.nn.BatchNorm2d(in_channels*2)\n","        self.conv3 = torch.nn.ConvTranspose2d(kernel_size=3, in_channels=in_channels*2, out_channels=in_channels,stride=2, padding=1, output_padding=1)\n","        \n","    def forward(self, inp):\n","        out = torch.nn.functional.relu(self.conv1(inp))\n","        out = self.bn2d1(out)\n","        out = torch.nn.functional.relu(self.conv2(out))\n","        out = self.bn2d2(out)\n","        out = torch.nn.functional.relu(self.conv3(out))\n","        return out"],"metadata":{"id":"ekLHNKLYgkRZ","executionInfo":{"status":"ok","timestamp":1675347783038,"user_tz":-180,"elapsed":1,"user":{"displayName":"Илья Андреевич","userId":"13920647134536331916"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["class UpSampling(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size=3):\n","        super().__init__()\n","        mid_channel = min(in_channels, out_channels) + max(in_channels, out_channels) - min(in_channels, out_channels)\n","        self.conv1 = torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=mid_channel, padding=1)\n","        self.bn2d1 = torch.nn.BatchNorm2d(mid_channel)\n","        self.conv2 = torch.nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=mid_channel, padding=1)\n","        self.bn2d2 = torch.nn.BatchNorm2d(mid_channel)\n","        self.conv3 = torch.nn.ConvTranspose2d(in_channels=mid_channel, out_channels=out_channels, kernel_size=3, stride=2, padding=1, output_padding=1)\n","        \n","    def forward(self, inp):\n","        out = torch.nn.functional.relu(self.conv1(inp))\n","        out = self.bn2d1(out)\n","        out = torch.nn.functional.relu(self.conv2(out))\n","        out = self.bn2d2(out)\n","        out = torch.nn.functional.relu(self.conv3(out))\n","        return out"],"metadata":{"id":"6DZyx33WgnAY","executionInfo":{"status":"ok","timestamp":1675347799998,"user_tz":-180,"elapsed":2,"user":{"displayName":"Илья Андреевич","userId":"13920647134536331916"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["class FinalBlock(nn.Module):\n","    def __init__(self, in_channels, mid_channel, out_channels, kernel_size=3):\n","        super().__init__()\n","        self.conv1 = torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=mid_channel, padding=1)\n","        self.bn2d1 = torch.nn.BatchNorm2d(mid_channel)\n","        self.conv2 = torch.nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=mid_channel, padding=1)\n","        self.bn2d2 = torch.nn.BatchNorm2d(mid_channel)\n","        self.conv3 = torch.nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=out_channels, padding=1)\n","        \n","    def forward(self, inp):\n","        out = torch.nn.functional.relu(self.conv1(inp))\n","        out = self.bn2d1(out)\n","        out = torch.nn.functional.relu(self.conv2(out))\n","        out = self.bn2d2(out)\n","        out = torch.nn.functional.sigmoid(self.conv3(out))\n","        return out"],"metadata":{"id":"GyNBdWQMgs45","executionInfo":{"status":"ok","timestamp":1675347810745,"user_tz":-180,"elapsed":1,"user":{"displayName":"Илья Андреевич","userId":"13920647134536331916"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["class UNet(nn.Module):    \n","    def __init__(self, in_channels, out_channels):\n","        super(UNet, self).__init__()\n","        self.conv1 = DownSampling(in_channels, 64, 3)\n","        self.conv2 = DownSampling(64, 128, 3)\n","        self.conv3 = DownSampling(128, 256, 3)\n","        self.bottleneck = Bottlenack(256)\n","        self.convT1 = UpSampling(in_channels=256,out_channels=192, kernel_size=3)\n","        self.convT2 = UpSampling(in_channels=192,out_channels=128, kernel_size=3)\n","        self.convT3 = UpSampling(in_channels=128,out_channels=96,  kernel_size=3)\n","        self.convT4 = UpSampling(in_channels=96, out_channels=64,  kernel_size=3)\n","        self.aspp = ASPPBlock(64)\n","        self.final = FinalBlock(64, 16, out_channels)\n","        self.conv_maxpool = torch.nn.MaxPool2d(kernel_size=2)\n","    \n","    def forward(self, x):\n","        #print(np.shape(x))\n","        x = self.conv1(x)\n","        x = self.conv_maxpool(x)\n","        #print(f\"conv1\", np.shape(x))\n","        x = self.conv2(x)\n","        x = self.conv_maxpool(x)\n","        #print(f\"conv2\", np.shape(x))\n","        x = self.conv3(x)\n","        x = self.conv_maxpool(x)\n","        #print(f\"conv3\", np.shape(x))\n","        x = self.bottleneck(x)\n","        #print(f\"bottleneck\", np.shape(x))\n","        x = self.convT1(x)\n","        #print(f\"convT1\", np.shape(x))\n","        x = self.convT2(x)\n","        #print(f\"convT2\", np.shape(x))\n","        x = self.convT3(x)\n","        #print(f\"convT3\", np.shape(x))\n","        x = self.convT4(x)\n","        #print(f\"convT4\", np.shape(x))\n","        #x = self.aspp(x)\n","        #print(f\"aspp\", np.shape(x))\n","        x = self.final(x)\n","        #print(f\"final\", np.shape(x))\n","        return x"],"metadata":{"id":"umeTiqldgv_k","executionInfo":{"status":"ok","timestamp":1675347823207,"user_tz":-180,"elapsed":2,"user":{"displayName":"Илья Андреевич","userId":"13920647134536331916"}}},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":["Импортируем библиотеки для Colab"],"metadata":{"id":"x3qZGE5viFFI"}},{"cell_type":"code","source":["from google.colab import drive\n","from google.colab import output # библиотеки для подгрузки с google Disk\n","drive.mount('/content/drive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aOzmaX4Hg-1P","executionInfo":{"status":"ok","timestamp":1675349565167,"user_tz":-180,"elapsed":3083,"user":{"displayName":"Илья Андреевич","userId":"13920647134536331916"}},"outputId":"57cc9cbb-9b16-434f-cfb9-7662167107b8"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["Импортируем обученные модели"],"metadata":{"id":"D9slreRUg_Rs"}},{"cell_type":"code","source":["# Импорт модели tensorFlow\n","try:\n","  model_tf = tf.keras.models.load_model('/content/drive/MyDrive/Докт24/3_local_test/model-tf-1')\n","  print('Модель > TensorFlow < успешно импортирована')\n","except:\n","  print('Модель не удалось импортировать')\n","\n","model_tf = keras.Sequential()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_y-vFdkIhGik","executionInfo":{"status":"ok","timestamp":1675347480366,"user_tz":-180,"elapsed":31180,"user":{"displayName":"Илья Андреевич","userId":"13920647134536331916"}},"outputId":"034d15ed-6613-4a98-b038-b292fa9536df"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Модель > TensorFlow < успешно импортирована\n"]}]},{"cell_type":"code","source":["model_tf_h5 = keras.models.load_model('/content/drive/MyDrive/Докт24/3_local_test/model-tf-1.h5')"],"metadata":{"id":"y1qLkhWznntA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Импорт модели PyTorch\n","learning_rate = 0.0001\n","\n","unet = UNet(in_channels=1,out_channels=5)\n","#if params['device'] != \"cpu\":\n","#unet = unet.to(params[\"device\"])\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(unet.parameters(), lr = learning_rate)\n","\n","model_tr = Model.load_state_dict(torch.load('/content/drive/MyDrive/Докт24/3_local_test/lung_shares_model.mdl'))\n","#model.load_state_dict(torch.load(Path))\n","\n","#load_state_dict(torch.load('/content/drive/MyDrive/Докт24/3_local_test/lung_shares_model.mdl'))\n","\n"],"metadata":{"id":"sx9jT3uxhGlO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Загружам набор данных для теста"],"metadata":{"id":"zGjhDhSfhQGb"}},{"cell_type":"code","source":["image_path = '/content/drive/MyDrive/Докт24/2_Lungs/Darwin/lungs/00000484_person820_virus_1456.png'\n","image_data = tf.io.gfile.GFile(image_path, 'rb').read()\n","image = Image.open(BytesIO(image_data))\n","(im_width, im_height) = image.size\n","k = np.array(image.getdata()).reshape((1, im_height, im_width, 3)).astype(np.uint8)\n","image_np = k\n","plt.figure(figsize=(24,32))\n","plt.imshow(image_np[0])\n","plt.show()"],"metadata":{"id":"0_ReIl7HhWXa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","img_path = '/content/drive/MyDrive/Докт24/2_Lungs/Darwin/lungs/00000484_person820_virus_1456.png'\n","\n","class_names=['adenocarcinoma', 'normal', 'large.cell', 'squamous.cell']\n","\n","img = tf.keras.utils.load_img(img_path, target_size=(300, 440, 3))\n","img_array = tf.keras.utils.img_to_array(img)\n","img_array = tf.expand_dims(img_array, 0)\n","\n","prediction = model_tf.predict(img_array)\n","\n","print( \n","    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n","    .format(class_names[np.argmax(prediction)], 100 * np.max(prediction))\n","      \n",")\n","\n","cv2.imread(image_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xPQUsOJfdxW0","executionInfo":{"status":"ok","timestamp":1675349483500,"user_tz":-180,"elapsed":3,"user":{"displayName":"Илья Андреевич","userId":"13920647134536331916"}},"outputId":"3c0367da-6776-419f-83d5-46bddc5eee3f"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n","This image most likely belongs to *** with a 251.00 percent confidence.\n"]},{"output_type":"execute_result","data":{"text/plain":["array([[[0, 0, 0],\n","        [0, 0, 0],\n","        [0, 0, 0],\n","        ...,\n","        [0, 0, 0],\n","        [0, 0, 0],\n","        [0, 0, 0]],\n","\n","       [[0, 0, 0],\n","        [0, 0, 0],\n","        [0, 0, 0],\n","        ...,\n","        [0, 0, 0],\n","        [0, 0, 0],\n","        [0, 0, 0]],\n","\n","       [[0, 0, 0],\n","        [0, 0, 0],\n","        [0, 0, 0],\n","        ...,\n","        [0, 0, 0],\n","        [0, 0, 0],\n","        [0, 0, 0]],\n","\n","       ...,\n","\n","       [[0, 0, 0],\n","        [0, 0, 0],\n","        [0, 0, 0],\n","        ...,\n","        [0, 0, 0],\n","        [0, 0, 0],\n","        [0, 0, 0]],\n","\n","       [[0, 0, 0],\n","        [0, 0, 0],\n","        [0, 0, 0],\n","        ...,\n","        [0, 0, 0],\n","        [0, 0, 0],\n","        [0, 0, 0]],\n","\n","       [[0, 0, 0],\n","        [0, 0, 0],\n","        [0, 0, 0],\n","        ...,\n","        [0, 0, 0],\n","        [0, 0, 0],\n","        [0, 0, 0]]], dtype=uint8)"]},"metadata":{},"execution_count":47}]},{"cell_type":"markdown","source":["Вывод результатов"],"metadata":{"id":"ImPm2JU4hWw-"}},{"cell_type":"code","source":[],"metadata":{"id":"t7y5GyIxhfTd"},"execution_count":null,"outputs":[]}]}