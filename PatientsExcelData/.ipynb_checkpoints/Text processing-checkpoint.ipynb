{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb68b97d",
   "metadata": {},
   "source": [
    "# Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7d6e64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pymystem3 import Mystem\n",
    "import re\n",
    "import transformers\n",
    "import nltk\n",
    "from tqdm import notebook\n",
    "import torch\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from dateutil.parser import parse\n",
    "from catboost import CatBoostClassifier, Pool, cv\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f4383d",
   "metadata": {},
   "source": [
    "## Данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab46461a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'chd — 100.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f40fba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admittion</th>\n",
       "      <th>department</th>\n",
       "      <th>discharge</th>\n",
       "      <th>sex</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>BMI</th>\n",
       "      <th>BSA</th>\n",
       "      <th>birth</th>\n",
       "      <th>Операции (все в ИБ)</th>\n",
       "      <th>...</th>\n",
       "      <th>Количество выб. из ОРИТ</th>\n",
       "      <th>К.дней в ОРИТ (всего)</th>\n",
       "      <th>ИВЛ, час. в ОРИТ (суммарно)</th>\n",
       "      <th>Инф. осложнения в ОРИТ</th>\n",
       "      <th>Назн. преп. в ОРИТ</th>\n",
       "      <th>target</th>\n",
       "      <th>Непосред. причина смерти</th>\n",
       "      <th>ЭхоКГ (Из Эпикр. вып.)</th>\n",
       "      <th>ЭКГ (Из Эпикр. вып.)</th>\n",
       "      <th>Назначения при выписке</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-12-12</td>\n",
       "      <td>ehn</td>\n",
       "      <td>2017-01-10</td>\n",
       "      <td>m</td>\n",
       "      <td>76</td>\n",
       "      <td>9.7</td>\n",
       "      <td>111.27</td>\n",
       "      <td>0.46</td>\n",
       "      <td>02.01.2016</td>\n",
       "      <td>12.12.2016: (Откр./ИК) Перевязка ранее наложен...</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>252</td>\n",
       "      <td>01.01.2017: пневмония</td>\n",
       "      <td>Адреналина г\\хл 0,1% 1мл №5; Аксетин 750мг №10...</td>\n",
       "      <td>recovery</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ЭхоКГ ВПС (02.12.2016 14:37:22, врач Неталиева...</td>\n",
       "      <td>ЭКГ (02.12.2016 16:43:25)\\nРитм сердца синусов...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   admittion department  discharge sex  height  weight     BMI   BSA  \\\n",
       "0 2016-12-12        ehn 2017-01-10   m      76     9.7  111.27  0.46   \n",
       "\n",
       "        birth                                Операции (все в ИБ)  ...  \\\n",
       "0  02.01.2016  12.12.2016: (Откр./ИК) Перевязка ранее наложен...  ...   \n",
       "\n",
       "  Количество выб. из ОРИТ К.дней в ОРИТ (всего) ИВЛ, час. в ОРИТ (суммарно)  \\\n",
       "0                       2                    20                         252   \n",
       "\n",
       "  Инф. осложнения в ОРИТ                                 Назн. преп. в ОРИТ  \\\n",
       "0  01.01.2017: пневмония  Адреналина г\\хл 0,1% 1мл №5; Аксетин 750мг №10...   \n",
       "\n",
       "     target Непосред. причина смерти   \\\n",
       "0  recovery                       NaN   \n",
       "\n",
       "                              ЭхоКГ (Из Эпикр. вып.)  \\\n",
       "0  ЭхоКГ ВПС (02.12.2016 14:37:22, врач Неталиева...   \n",
       "\n",
       "                                ЭКГ (Из Эпикр. вып.) Назначения при выписке  \n",
       "0  ЭКГ (02.12.2016 16:43:25)\\nРитм сердца синусов...                         \n",
       "\n",
       "[1 rows x 43 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel(file_path)\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "368b2aae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99 entries, 0 to 98\n",
      "Data columns (total 43 columns):\n",
      " #   Column                                           Non-Null Count  Dtype         \n",
      "---  ------                                           --------------  -----         \n",
      " 0   admittion                                        99 non-null     datetime64[ns]\n",
      " 1   department                                       99 non-null     object        \n",
      " 2   discharge                                        99 non-null     datetime64[ns]\n",
      " 3   sex                                              99 non-null     object        \n",
      " 4   height                                           99 non-null     int64         \n",
      " 5   weight                                           99 non-null     float64       \n",
      " 6   BMI                                              99 non-null     float64       \n",
      " 7   BSA                                              99 non-null     float64       \n",
      " 8   birth                                            99 non-null     object        \n",
      " 9   Операции (все в ИБ)                              99 non-null     object        \n",
      " 10  Перенесенные опер. (из Анамн.)                   99 non-null     object        \n",
      " 11  Диагноз                                          99 non-null     object        \n",
      " 12  МКБ                                              99 non-null     object        \n",
      " 13  Соп. забол. (из Анамн.)                          99 non-null     object        \n",
      " 14  Медикам. леч. по поводу осн. забол. (из Анамн.)  87 non-null     object        \n",
      " 15  Принимаемые препараты (из Анамн.)                66 non-null     object        \n",
      " 16  ЭхоКГ (Из Эпикр. до опер.)                       96 non-null     object        \n",
      " 17  ЭКГ (Из Эпикр. до опер.)                         93 non-null     object        \n",
      " 18  АКГ (Из Эпикр. до опер.)                         51 non-null     object        \n",
      " 19  КТ (Из Эпикр. до опер.)                          14 non-null     object        \n",
      " 20  Операция (основная / первая в ИБ)                99 non-null     object        \n",
      " 21  Дата опер.                                       99 non-null     object        \n",
      " 22  Тип опер.                                        99 non-null     object        \n",
      " 23  Протокол                                         98 non-null     object        \n",
      " 24  Время ИК, мин.                                   99 non-null     object        \n",
      " 25  Время ПерАо, мин.                                55 non-null     float64       \n",
      " 26  Осложнения опер.                                 0 non-null      float64       \n",
      " 27  Смерть на опер. столе                            1 non-null      object        \n",
      " 28  Хирургические ман.                               22 non-null     object        \n",
      " 29  Поступил в ОРИТ                                  99 non-null     object        \n",
      " 30  Выбыл из ОРИТ                                    99 non-null     object        \n",
      " 31  Умер в ОРИТ                                      99 non-null     object        \n",
      " 32  Количество пост. в ОРИТ                          99 non-null     int64         \n",
      " 33  Количество выб. из ОРИТ                          99 non-null     int64         \n",
      " 34  К.дней в ОРИТ (всего)                            99 non-null     int64         \n",
      " 35  ИВЛ, час. в ОРИТ (суммарно)                      99 non-null     int64         \n",
      " 36  Инф. осложнения в ОРИТ                           70 non-null     object        \n",
      " 37  Назн. преп. в ОРИТ                               83 non-null     object        \n",
      " 38  target                                           99 non-null     object        \n",
      " 39  Непосред. причина смерти                         5 non-null      object        \n",
      " 40  ЭхоКГ (Из Эпикр. вып.)                           97 non-null     object        \n",
      " 41  ЭКГ (Из Эпикр. вып.)                             91 non-null     object        \n",
      " 42  Назначения при выписке                           99 non-null     object        \n",
      "dtypes: datetime64[ns](2), float64(5), int64(5), object(31)\n",
      "memory usage: 33.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a867e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ehn     46\n",
       "onik    32\n",
       "rhn     21\n",
       "Name: department, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['department'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ef7eef",
   "metadata": {},
   "source": [
    "Для теста возьмем только один столбец - диагноз"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b955f94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis = data['Диагноз']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6a62188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'двойное отхождение аорты и легочной артерии от правого желудочка, подаортальный дефект межжелудочковой перегородки, комбинированный стеноз легочной артерии, умеренные сужения устьев правой и левой  легочных артерий; ОАП, НК 0-1 ст, артериальная гипоксемия, состояние после ТЛБВП 15.08.2016, клапана ЛА, с-м Дауна, с-м мышечной гипотонии, гипертензионно-гидроцефальный с-м; 18.01.2017 - ОПЕРАЦИЯ: радикальная коррекция двойного отхождения магистральных сосудов от правого желудочка с пластикой выводного отдела правого желудочка и ствола легочной артерии ксеноперикардиальной заплатой; перевязка открытого артериального протока; в условиях ИК, гипотеремии, НК 2а ст'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagnosis[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130c87a3",
   "metadata": {},
   "source": [
    "## Пример применения TF-IDF на столбце \"Диагноз\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efa21ae",
   "metadata": {},
   "source": [
    "### Гипотетический способ отчистки конкретных элементов текста (например даты)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f424acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nDAY = r'(?:[0-3]?\\d)'\n",
    "nMNTH = r'(?:11|12|10|0?[1-9])' \n",
    "nYR = r'(?:(?:19|20)\\d\\d)'\n",
    "nDELIM = r'(?:[\\/\\-\\._])?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29ba7e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'двойное отхождение аорты и легочной артерии от правого желудочка, подаортальный дефект межжелудочковой перегородки, комбинированный стеноз легочной артерии, умеренные сужения устьев правой и левой  легочных артерий; ОАП, НК 0-1 ст, артериальная гипоксемия, состояние после ТЛБВП  , клапана ЛА, с-м Дауна, с-м мышечной гипотонии, гипертензионно-гидроцефальный с-м;   - ОПЕРАЦИЯ: радикальная коррекция двойного отхождения магистральных сосудов от правого желудочка с пластикой выводного отдела правого желудочка и ствола легочной артерии ксеноперикардиальной заплатой; перевязка открытого артериального протока; в условиях ИК, гипотеремии, НК 2а ст'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(f'(?:{nDAY}{nDELIM}{nMNTH}{nDELIM}{nYR})', ' ', diagnosis[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ba3560",
   "metadata": {},
   "source": [
    "### Лемментизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d674877",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Mystem()\n",
    "\n",
    "# Леммантизирует текст\n",
    "def lemmatize(text):\n",
    "    return \"\".join(m.lemmatize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24df0709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'двойной отхождение аорта и легочный артерия от правый желудочек, подаортальный дефект межжелудочковый перегородка, комбинированный стеноз легочный артерия, умеренный сужение устье правый и левый  легочный артерия; оап, НК 0-1 ст, артериальный гипоксемия, состояние после ТЛБВП 15.08.2016, клапан ЛА, с-м даун, с-м мышечный гипотония, гипертензионный-гидроцефальный с-м; 18.01.2017 - операция: радикальный коррекция двойной отхождение магистральный сосуд от правый желудочек с пластика выводной отдел правый желудочек и ствол легочный артерия ксеноперикардиальный заплата; перевязка открытый артериальный проток; в условие ик, гипотеремия, НК 2а ст\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize(diagnosis[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c84bf8",
   "metadata": {},
   "source": [
    "### Отчистка текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff999cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чистит текст от всего, кроме русских и английских букв\n",
    "def clear_text(text):\n",
    "    cleaned = re.sub(r'[^а-яА-Яa-zA-ZёЁ ]', ' ', text)\n",
    "    cleaned = cleaned.split()\n",
    "    return ' '.join(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c06ce7d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'двойной отхождение аорта и легочный артерия от правый желудочек подаортальный дефект межжелудочковый перегородка комбинированный стеноз легочный артерия умеренный сужение устье правый и левый легочный артерия оап НК ст артериальный гипоксемия состояние после ТЛБВП клапан ЛА с м даун с м мышечный гипотония гипертензионный гидроцефальный с м операция радикальный коррекция двойной отхождение магистральный сосуд от правый желудочек с пластика выводной отдел правый желудочек и ствол легочный артерия ксеноперикардиальный заплата перевязка открытый артериальный проток в условие ик гипотеремия НК а ст'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_text(lemmatize(diagnosis[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7913144b",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13f5a9d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Стивен\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21b48a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(nltk_stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d019d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "corpus = diagnosis.apply(lambda x: clear_text(lemmatize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84065fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer(stop_words=stopwords).fit(corpus)\n",
    "tf_idf_train = tf_idf.transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7379ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_train.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a2626b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcf4d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_vocab = pd.DataFrame([[i, j] for i, j in tf_idf.vocabulary_.items()], columns=['word', 'index'])\n",
    "tf_idf_vocab = tf_idf_vocab.set_index('index')\n",
    "tf_idf_vocab = tf_idf_vocab.sort_index()\n",
    "tf_idf_vocab.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6811e832",
   "metadata": {},
   "source": [
    "## RuBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ea9c0ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c507d3dba2344bdae623dc70d035fe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/683M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at sberbank-ai/ruBert-base were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"sberbank-ai/ruBert-base\")\n",
    "\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"sberbank-ai/ruBert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e75be1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = corpus.apply(lambda x: tokenizer.encode(x, add_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "7dfb35ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e5b0763f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   101,    116,   2991,  74639, 113404,    666,    107,  30545,\n",
       "        12866,    378,  31338,    390,   1996,  89679,  20900,    378,\n",
       "        71738,   5635,  62761,    701,  10429,    391,    378,  39381,\n",
       "          657,   3526,  91552,    378,  73147,    667,    378,  36986,\n",
       "          396,  30545,  12866,    378,  31338,    390,  61896,  52065,\n",
       "         6056,  91706,  20900,    378,  73147,  11894, 113404,  91645,\n",
       "         1277,  12866,    378,  22389,   2154,  20900,    378,  31338,\n",
       "          390,    700,  80548,    755,    378, 113404,    666,    114,\n",
       "         4984,   2160,  12020,   5762,    934,  11803,  45165,   9309,\n",
       "        41156,    667,    378,  30545,  12866,    378,   3904,   2968,\n",
       "         4211,  13474,    108,    385,    106,  11894,  99540,    667,\n",
       "          378,  31338,    922,    667,    378,  31053,  69367,   5917,\n",
       "        11803,  71738,   5635,   8838,   3624,  33988,    378,  39381,\n",
       "          657,  83047,    660,  30545,  12866,    378,  31338,    390,\n",
       "          108,    385,    106,  11894,  31338,    922,    667,    378,\n",
       "        31053,  69367,   5917,    102,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded = np.array([i + [0] * (max_len - len(i)) for i in tokenized.values])\n",
    "\n",
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "padded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "e4249dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef4426063f324cd19c7e69baf9d1507c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 0\n",
      "Stage 1\n",
      "Stage 2\n",
      "Stage 3\n",
      "Stage 4\n",
      "Stage 5\n",
      "Stage 6\n",
      "Stage 7\n",
      "Stage 8\n",
      "Stage 9\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "embeddings = []\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "    batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)])\n",
    "    attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "    \n",
    "    print(f'Stage {i}')\n",
    "    with torch.no_grad():\n",
    "        batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "    \n",
    "    embeddings.append(batch_embeddings[0][:,0,:].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "4a4c910f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.concatenate(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "5afb983e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 120138)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3684a9",
   "metadata": {},
   "source": [
    "Получилось 120000 признаков. Векторизация 100 примеров проход **Надо использовать модель с меньшим словарем, желательно из медицинских терминов.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99d00ec",
   "metadata": {},
   "source": [
    "## Тест модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124629a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = tf_idf_train, data['department']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e7ee1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859f4264",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(loss_function='MultiClass', verbose=100)\n",
    "model = model.fit(X_train, y_train, eval_set=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9c8c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_vocab['importance'] = model.get_feature_importance()\n",
    "tf_idf_vocab_sorted = tf_idf_vocab.sort_values(by='importance', ascending=False)\n",
    "tf_idf_vocab_sorted.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb013900",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc770c9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cat_score = cross_val_score(model, X, y)\n",
    "cat_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9a5f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5881d9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model = DummyClassifier().fit(X_train, y_train)\n",
    "print(classification_report(y_test, dummy_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d311d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(DummyClassifier(), X, y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d15c0f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
