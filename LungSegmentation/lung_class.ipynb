{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e31e91b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SimpleITK in /home/arhitegio/anaconda3/lib/python3.9/site-packages (2.2.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install SimpleITK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcd9da49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydicom in /home/arhitegio/anaconda3/lib/python3.9/site-packages (2.3.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pydicom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1196ac79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fill_voids\n",
      "  Downloading fill_voids-2.0.2-cp39-cp39-manylinux2010_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/arhitegio/anaconda3/lib/python3.9/site-packages (from fill_voids) (1.23.4)\n",
      "Collecting fastremap\n",
      "  Downloading fastremap-1.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: fastremap, fill_voids\n",
      "Successfully installed fastremap-1.13.3 fill_voids-2.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install fill_voids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e0e0e0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import argparse\n",
    "import logging\n",
    "import warnings\n",
    "import os\n",
    "import SimpleITK as sitk\n",
    "import pkg_resources\n",
    "import numpy as np\n",
    "import scipy.ndimage as ndimage\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import pydicom as pyd\n",
    "from tqdm import tqdm\n",
    "import fill_voids\n",
    "import skimage\n",
    "import skimage.morphology\n",
    "import skimage.measure\n",
    "from pydicom.dataelem import DataElement\n",
    "\n",
    "#from .resunet import UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "db0b93ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#V\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# stores urls and number of classes of the models\n",
    "model_urls = {('unet', 'R231'): ('unet_r231-d5d2fc3d.pth', 3),\n",
    "              ('unet', 'LTRCLobes'): (\n",
    "                  'unet_ltrclobes-3a07043d.pth', 6),\n",
    "              ('unet', 'R231CovidWeb'): (\n",
    "                  'unet_r231covid-0de78a7e.pth', 3)}\n",
    "\n",
    "\n",
    "def apply(image, model=None, force_cpu=False, batch_size=20, volume_postprocessing=True, noHU=False):\n",
    "    if model is None:\n",
    "        model = get_model('unet', 'R231')\n",
    "    \n",
    "    numpy_mode = isinstance(image, np.ndarray)\n",
    "    if numpy_mode:\n",
    "        inimg_raw = image.copy()\n",
    "    else:\n",
    "        inimg_raw = sitk.GetArrayFromImage(image)\n",
    "        directions = np.asarray(image.GetDirection())\n",
    "        if len(directions) == 9:\n",
    "            inimg_raw = np.flip(inimg_raw, np.where(directions[[0,4,8]][::-1]<0)[0])\n",
    "    del image\n",
    "\n",
    "    if force_cpu:\n",
    "        device = torch.device('cpu')\n",
    "    else:\n",
    "        if torch.cuda.is_available():\n",
    "            device = torch.device('cuda')\n",
    "        else:\n",
    "            logging.info(\"No GPU support available, will use CPU. Note, that this is significantly slower!\")\n",
    "            batch_size = 1\n",
    "            device = torch.device('cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    \n",
    "    if not noHU:\n",
    "        tvolslices, xnew_box = preprocess(inimg_raw, resolution=[256, 256])\n",
    "        tvolslices[tvolslices > 600] = 600\n",
    "        tvolslices = np.divide((tvolslices + 1024), 1624)\n",
    "    else:\n",
    "        # support for non HU images. This is just a hack. The models were not trained with this in mind\n",
    "        tvolslices = skimage.color.rgb2gray(inimg_raw)\n",
    "        tvolslices = skimage.transform.resize(tvolslices, [256, 256])\n",
    "        tvolslices = np.asarray([tvolslices*x for x in np.linspace(0.3,2,20)])\n",
    "        tvolslices[tvolslices>1] = 1\n",
    "        sanity = [(tvolslices[x]>0.6).sum()>25000 for x in range(len(tvolslices))]\n",
    "        tvolslices = tvolslices[sanity]\n",
    "    torch_ds_val = LungLabelsDS_inf(tvolslices)\n",
    "    dataloader_val = torch.utils.data.DataLoader(torch_ds_val, batch_size=batch_size, shuffle=False, pin_memory=False)\n",
    "\n",
    "    timage_res = np.empty((np.append(0, tvolslices[0].shape)), dtype=np.uint8)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X in tqdm(dataloader_val):\n",
    "            X = X.float().to(device)\n",
    "            prediction = model(X)\n",
    "            pls = torch.max(prediction, 1)[1].detach().cpu().numpy().astype(np.uint8)\n",
    "            timage_res = np.vstack((timage_res, pls))\n",
    "\n",
    "    # postprocessing includes removal of small connected components, hole filling and mapping of small components to\n",
    "    # neighbors\n",
    "    if volume_postprocessing:\n",
    "        outmask = postrocessing(timage_res)\n",
    "    else:\n",
    "        outmask = timage_res\n",
    "\n",
    "    if noHU:\n",
    "        outmask = skimage.transform.resize(outmask[np.argmax((outmask==1).sum(axis=(1,2)))], inimg_raw.shape[:2], order=0, anti_aliasing=False, preserve_range=True)[None,:,:]\n",
    "    else:\n",
    "         outmask = np.asarray(\n",
    "            [reshape_mask(outmask[i], xnew_box[i], inimg_raw.shape[1:]) for i in range(outmask.shape[0])],\n",
    "            dtype=np.uint8)\n",
    "    \n",
    "    if not numpy_mode:\n",
    "        if len(directions) == 9:\n",
    "            outmask = np.flip(outmask, np.where(directions[[0,4,8]][::-1]<0)[0])    \n",
    "    \n",
    "    return outmask.astype(np.uint8)\n",
    "\n",
    "\n",
    "def get_model(modeltype, modelname, modelpath=None, n_classes=3):\n",
    "    if modelpath is None:\n",
    "        model_url, n_classes = model_urls[(modeltype, modelname)]\n",
    "        state_dict = torch.load(model_url, map_location=torch.device('cpu'))\n",
    "        # state_dict = torch.hub.load_state_dict_from_url(model_url, progress=True, map_location=torch.device('cpu'))\n",
    "    else:\n",
    "        state_dict = torch.load(modelpath, map_location=torch.device('cpu'))\n",
    "\n",
    "    if modeltype == 'unet':\n",
    "        model = UNet(n_classes=n_classes, padding=True, depth=5, up_mode='upsample', batch_norm=True, residual=False)\n",
    "    elif modeltype == 'resunet':\n",
    "        model = UNet(n_classes=n_classes, padding=True, depth=5, up_mode='upsample', batch_norm=True, residual=True)\n",
    "    else:\n",
    "        logging.exception(f\"Model {modelname} not known\")\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "def apply_fused(image, basemodel = 'LTRCLobes', fillmodel = 'R231', force_cpu=False, batch_size=20, volume_postprocessing=True, noHU=False):\n",
    "    '''Will apply basemodel and use fillmodel to mitiage false negatives'''\n",
    "    mdl_r = get_model('unet',fillmodel)\n",
    "    mdl_l = get_model('unet',basemodel)\n",
    "    logging.info(\"Apply: %s\" % basemodel)\n",
    "    res_l = apply(image, mdl_l, force_cpu=force_cpu, batch_size=batch_size,  volume_postprocessing=volume_postprocessing, noHU=noHU)\n",
    "    logging.info(\"Apply: %s\" % fillmodel)\n",
    "    res_r = apply(image, mdl_r, force_cpu=force_cpu, batch_size=batch_size,  volume_postprocessing=volume_postprocessing, noHU=noHU)\n",
    "    spare_value = res_l.max()+1\n",
    "    res_l[np.logical_and(res_l==0, res_r>0)] = spare_value\n",
    "    res_l[res_r==0] = 0\n",
    "    logging.info(\"Fusing results... this may take up to several minutes!\")\n",
    "    return postrocessing(res_l, spare=[spare_value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1a15959e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, n_classes=2, depth=5, wf=6, padding=False,\n",
    "                 batch_norm=False, up_mode='upconv', residual=False):\n",
    "        \"\"\"\n",
    "        Implementation of\n",
    "        U-Net: Convolutional Networks for Biomedical Image Segmentation\n",
    "        (Ronneberger et al., 2015)\n",
    "        https://arxiv.org/abs/1505.04597\n",
    "        Using the default arguments will yield the exact version used\n",
    "        in the original paper\n",
    "        Args:\n",
    "            in_channels (int): number of input channels\n",
    "            n_classes (int): number of output channels\n",
    "            depth (int): depth of the network\n",
    "            wf (int): number of filters in the first layer is 2**wf\n",
    "            padding (bool): if True, apply padding such that the input shape\n",
    "                            is the same as the output.\n",
    "                            This may introduce artifacts\n",
    "            batch_norm (bool): Use BatchNorm after layers with an\n",
    "                               activation function\n",
    "            up_mode (str): one of 'upconv' or 'upsample'.\n",
    "                           'upconv' will use transposed convolutions for\n",
    "                           learned upsampling.\n",
    "                           'upsample' will use bilinear upsampling.\n",
    "            residual: if True, residual connections will be added\n",
    "        \"\"\"\n",
    "        super(UNet, self).__init__()\n",
    "        assert up_mode in ('upconv', 'upsample')\n",
    "        self.padding = padding\n",
    "        self.depth = depth\n",
    "        prev_channels = in_channels\n",
    "        self.down_path = nn.ModuleList()\n",
    "        for i in range(depth):\n",
    "            if i == 0 and residual:\n",
    "                self.down_path.append(UNetConvBlock(prev_channels, 2 ** (wf + i),\n",
    "                                                    padding, batch_norm, residual, first=True))\n",
    "            else:\n",
    "                self.down_path.append(UNetConvBlock(prev_channels, 2 ** (wf + i),\n",
    "                                                    padding, batch_norm, residual))\n",
    "            prev_channels = 2 ** (wf + i)\n",
    "\n",
    "        self.up_path = nn.ModuleList()\n",
    "        for i in reversed(range(depth - 1)):\n",
    "            self.up_path.append(UNetUpBlock(prev_channels, 2 ** (wf + i), up_mode,\n",
    "                                            padding, batch_norm, residual))\n",
    "            prev_channels = 2 ** (wf + i)\n",
    "\n",
    "        self.last = nn.Conv2d(prev_channels, n_classes, kernel_size=1)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        blocks = []\n",
    "        for i, down in enumerate(self.down_path):\n",
    "            x = down(x)\n",
    "            if i != len(self.down_path) - 1:\n",
    "                blocks.append(x)\n",
    "                x = F.avg_pool2d(x, 2)\n",
    "\n",
    "        for i, up in enumerate(self.up_path):\n",
    "            x = up(x, blocks[-i - 1])\n",
    "\n",
    "        res = self.last(x)\n",
    "        return self.softmax(res)\n",
    "\n",
    "\n",
    "class UNetConvBlock(nn.Module):\n",
    "    def __init__(self, in_size, out_size, padding, batch_norm, residual=False, first=False):\n",
    "        super(UNetConvBlock, self).__init__()\n",
    "        self.residual = residual\n",
    "        self.out_size = out_size\n",
    "        self.in_size = in_size\n",
    "        self.batch_norm = batch_norm\n",
    "        self.first = first\n",
    "        self.residual_input_conv = nn.Conv2d(self.in_size, self.out_size, kernel_size=1)\n",
    "        self.residual_batchnorm = nn.BatchNorm2d(self.out_size)\n",
    "\n",
    "        if residual:\n",
    "            padding = 1\n",
    "        block = []\n",
    "\n",
    "        if residual and not first:\n",
    "            block.append(nn.ReLU())\n",
    "            if batch_norm:\n",
    "                block.append(nn.BatchNorm2d(in_size))\n",
    "\n",
    "        block.append(nn.Conv2d(in_size, out_size, kernel_size=3,\n",
    "                               padding=int(padding)))\n",
    "        block.append(nn.ReLU())\n",
    "        if batch_norm:\n",
    "            block.append(nn.BatchNorm2d(out_size))\n",
    "\n",
    "        block.append(nn.Conv2d(out_size, out_size, kernel_size=3,\n",
    "                               padding=int(padding)))\n",
    "\n",
    "        if not residual:\n",
    "            block.append(nn.ReLU())\n",
    "            if batch_norm:\n",
    "                block.append(nn.BatchNorm2d(out_size))\n",
    "        self.block = nn.Sequential(*block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.block(x)\n",
    "        if self.residual:\n",
    "            if self.in_size != self.out_size:\n",
    "                x = self.residual_input_conv(x)\n",
    "                x = self.residual_batchnorm(x)\n",
    "            out = out + x\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class UNetUpBlock(nn.Module):\n",
    "    def __init__(self, in_size, out_size, up_mode, padding, batch_norm, residual=False):\n",
    "        super(UNetUpBlock, self).__init__()\n",
    "        self.residual = residual\n",
    "        self.in_size = in_size\n",
    "        self.out_size = out_size\n",
    "        self.residual_input_conv = nn.Conv2d(self.in_size, self.out_size, kernel_size=1)\n",
    "        self.residual_batchnorm = nn.BatchNorm2d(self.out_size)\n",
    "\n",
    "        if up_mode == 'upconv':\n",
    "            self.up = nn.ConvTranspose2d(in_size, out_size, kernel_size=2,\n",
    "                                         stride=2)\n",
    "        elif up_mode == 'upsample':\n",
    "            self.up = nn.Sequential(nn.Upsample(mode='bilinear', scale_factor=2),\n",
    "                                    nn.Conv2d(in_size, out_size, kernel_size=1))\n",
    "\n",
    "        self.conv_block = UNetConvBlock(in_size, out_size, padding, batch_norm)\n",
    "\n",
    "    @staticmethod\n",
    "    def center_crop(layer, target_size):\n",
    "        _, _, layer_height, layer_width = layer.size()\n",
    "        diff_y = (layer_height - target_size[0]) // 2\n",
    "        diff_x = (layer_width - target_size[1]) // 2\n",
    "        return layer[:, :, diff_y:(diff_y + target_size[0]), diff_x:(diff_x + target_size[1])]\n",
    "\n",
    "    def forward(self, x, bridge):\n",
    "        up = self.up(x)\n",
    "        crop1 = self.center_crop(bridge, up.shape[2:])\n",
    "        out_orig = torch.cat([up, crop1], 1)\n",
    "        out = self.conv_block(out_orig)\n",
    "        if self.residual:\n",
    "            if self.in_size != self.out_size:\n",
    "                out_orig = self.residual_input_conv(out_orig)\n",
    "                out_orig = self.residual_batchnorm(out_orig)\n",
    "            out = out + out_orig\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4b402f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess(img, label=None, resolution=[192, 192]):\n",
    "    imgmtx = np.copy(img)\n",
    "    lblsmtx = np.copy(label)\n",
    "\n",
    "    imgmtx[imgmtx < -1024] = -1024\n",
    "    imgmtx[imgmtx > 600] = 600\n",
    "    cip_xnew = []\n",
    "    cip_box = []\n",
    "    cip_mask = []\n",
    "    for i in range(imgmtx.shape[0]):\n",
    "        if label is None:\n",
    "            (im, m, box) = crop_and_resize(imgmtx[i, :, :], width=resolution[0], height=resolution[1])\n",
    "        else:\n",
    "            (im, m, box) = crop_and_resize(imgmtx[i, :, :], mask=lblsmtx[i, :, :], width=resolution[0],\n",
    "                                           height=resolution[1])\n",
    "            cip_mask.append(m)\n",
    "        cip_xnew.append(im)\n",
    "        cip_box.append(box)\n",
    "    if label is None:\n",
    "        return np.asarray(cip_xnew), cip_box\n",
    "    else:\n",
    "        return np.asarray(cip_xnew), cip_box, np.asarray(cip_mask)\n",
    "\n",
    "\n",
    "def simple_bodymask(img):\n",
    "    maskthreshold = -500\n",
    "    oshape = img.shape\n",
    "    img = ndimage.zoom(img, 0.25, order=0)\n",
    "    bodymask = img > maskthreshold\n",
    "    bodymask = ndimage.binary_closing(bodymask)\n",
    "    bodymask = ndimage.binary_fill_holes(bodymask, structure=np.ones((3, 3))).astype(int)\n",
    "    bodymask = ndimage.binary_erosion(bodymask, iterations=2)\n",
    "    bodymask = skimage.measure.label(bodymask.astype(int), connectivity=1)\n",
    "    regions = skimage.measure.regionprops(bodymask.astype(int))\n",
    "    if len(regions) > 0:\n",
    "        max_region = np.argmax(list(map(lambda x: x.area, regions))) + 1\n",
    "        bodymask = bodymask == max_region\n",
    "        bodymask = ndimage.binary_dilation(bodymask, iterations=2)\n",
    "    real_scaling = np.divide(oshape, img.shape)[0]\n",
    "    return ndimage.zoom(bodymask, real_scaling, order=0)\n",
    "\n",
    "\n",
    "def crop_and_resize(img, mask=None, width=192, height=192):\n",
    "    bmask = simple_bodymask(img)\n",
    "    # img[bmask==0] = -1024 # this line removes background outside of the lung.\n",
    "    # However, it has been shown problematic with narrow circular field of views that touch the lung.\n",
    "    # Possibly doing more harm than help\n",
    "    reg = skimage.measure.regionprops(skimage.measure.label(bmask))\n",
    "    if len(reg) > 0:\n",
    "        bbox = reg[0].bbox\n",
    "    else:\n",
    "        bbox = (0, 0, bmask.shape[0], bmask.shape[1])\n",
    "    img = img[bbox[0]:bbox[2], bbox[1]:bbox[3]]\n",
    "    img = ndimage.zoom(img, np.asarray([width, height]) / np.asarray(img.shape), order=1)\n",
    "    if not mask is None:\n",
    "        mask = mask[bbox[0]:bbox[2], bbox[1]:bbox[3]]\n",
    "        mask = ndimage.zoom(mask, np.asarray([width, height]) / np.asarray(mask.shape), order=0)\n",
    "        # mask = ndimage.binary_closing(mask,iterations=5)\n",
    "    return img, mask, bbox\n",
    "\n",
    "\n",
    "## For some reasons skimage.transform leads to edgy mask borders compared to ndimage.zoom\n",
    "# def reshape_mask(mask, tbox, origsize):\n",
    "#     res = np.ones(origsize) * 0\n",
    "#     resize = [tbox[2] - tbox[0], tbox[3] - tbox[1]]\n",
    "#     imgres = skimage.transform.resize(mask, resize, order=0, mode='constant', cval=0, anti_aliasing=False, preserve_range=True)\n",
    "#     res[tbox[0]:tbox[2], tbox[1]:tbox[3]] = imgres\n",
    "#     return res\n",
    "\n",
    "\n",
    "def reshape_mask(mask, tbox, origsize):\n",
    "    res = np.ones(origsize) * 0\n",
    "    resize = [tbox[2] - tbox[0], tbox[3] - tbox[1]]\n",
    "    imgres = ndimage.zoom(mask, resize / np.asarray(mask.shape), order=0)\n",
    "    res[tbox[0]:tbox[2], tbox[1]:tbox[3]] = imgres\n",
    "    return res\n",
    "\n",
    "\n",
    "class LungLabelsDS_inf(Dataset):\n",
    "    def __init__(self, ds):\n",
    "        self.dataset = ds\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx, None, :, :].astype(np.float64)\n",
    "\n",
    "\n",
    "def read_dicoms(path, primary=True, original=True):\n",
    "    allfnames = []\n",
    "    for dir, _, fnames in os.walk(path):\n",
    "        [allfnames.append(os.path.join(dir, fname)) for fname in fnames]\n",
    "\n",
    "    dcm_header_info = []\n",
    "    dcm_parameters = []\n",
    "    unique_set = []  # need this because too often there are duplicates of dicom files with different names\n",
    "    i = 0\n",
    "    for fname in tqdm(allfnames):\n",
    "        filename_ = os.path.splitext(os.path.split(fname)[1])\n",
    "        i += 1\n",
    "        if filename_[0] != 'DICOMDIR':\n",
    "            try:\n",
    "                dicom_header = pyd.dcmread(fname, defer_size=100, stop_before_pixels=True, force=True)\n",
    "                if dicom_header is not None:\n",
    "                    if 'ImageType' in dicom_header:\n",
    "                        #data_elemeint = DataElement('ImagePositionPatient',  'SQ', '---')\n",
    "                        #dicom_header.add(data_elemeint)\n",
    "                        if primary:\n",
    "                            is_primary = all([x in dicom_header.ImageType for x in ['PRIMARY']])\n",
    "                        else:\n",
    "                            is_primary = True\n",
    "\n",
    "                        if original:\n",
    "                            is_original = all([x in dicom_header.ImageType for x in ['ORIGINAL']])\n",
    "                        else:\n",
    "                            is_original = True\n",
    "\n",
    "                        # if 'ConvolutionKernel' in dicom_header:\n",
    "                        #     ck = dicom_header.ConvolutionKernel\n",
    "                        # else:\n",
    "                        #     ck = 'unknown'\n",
    "                        if is_primary and is_original and 'LOCALIZER' not in dicom_header.ImageType:\n",
    "                            h_info_wo_name = [dicom_header.StudyInstanceUID, dicom_header.SeriesInstanceUID,\n",
    "                                              '---']\n",
    "                            h_info = [dicom_header.StudyInstanceUID, dicom_header.SeriesInstanceUID, fname,\n",
    "                                      '---']\n",
    "                            #h_info = [dicom_header.StudyInstanceUID, dicom_header.SeriesInstanceUID, fname,\n",
    "                            #          dicom_header.ImagePositionPatient]\n",
    "                            if h_info_wo_name not in unique_set:\n",
    "                                unique_set.append(h_info_wo_name)\n",
    "                                dcm_header_info.append(h_info)\n",
    "                                # kvp = None\n",
    "                                # if 'KVP' in dicom_header:\n",
    "                                #     kvp = dicom_header.KVP\n",
    "                                # dcm_parameters.append([ck, kvp,dicom_header.SliceThickness])\n",
    "            except Exception as e:\n",
    "                logging.error(\"Unexpected error:\", sys.exc_info()[0])\n",
    "                logging.warning(\"Doesn't seem to be DICOM, will be skipped: \", fname)\n",
    "\n",
    "    conc = [x[1] for x in dcm_header_info]\n",
    "    sidx = np.argsort(conc)\n",
    "    conc = np.asarray(conc)[sidx]\n",
    "    dcm_header_info = np.asarray(dcm_header_info, dtype=object)[sidx]\n",
    "    # dcm_parameters = np.asarray(dcm_parameters)[sidx]\n",
    "    vol_unique = np.unique(conc, return_index=1, return_inverse=1)  # unique volumes\n",
    "    n_vol = len(vol_unique[1])\n",
    "    logging.info('There are ' + str(n_vol) + ' volumes in the study')\n",
    "\n",
    "    relevant_series = []\n",
    "    relevant_volumes = []\n",
    "\n",
    "    for i in range(len(vol_unique[1])):\n",
    "        curr_vol = i\n",
    "        info_idxs = np.where(vol_unique[2] == curr_vol)[0]\n",
    "        vol_files = dcm_header_info[info_idxs, 2]\n",
    "        positions = np.asarray([np.asarray(x[2]) for x in dcm_header_info[info_idxs, 3]])\n",
    "        slicesort_idx = np.argsort(positions)\n",
    "        vol_files = vol_files[slicesort_idx]\n",
    "        relevant_series.append(vol_files)\n",
    "        reader = sitk.ImageSeriesReader()\n",
    "        reader.SetFileNames(vol_files)\n",
    "        vol = reader.Execute()\n",
    "        relevant_volumes.append(vol)\n",
    "\n",
    "    return relevant_volumes\n",
    "\n",
    "def get_input_image(path):\n",
    "    if os.path.isfile(path):\n",
    "        logging.info(f'Read input: {path}')\n",
    "        input_image = sitk.ReadImage(path)\n",
    "    else:\n",
    "        logging.info(f'Looking for dicoms in {path}')\n",
    "        dicom_vols = read_dicoms(path, original=False, primary=False)\n",
    "        if len(dicom_vols) < 1:\n",
    "            sys.exit('No dicoms found!')\n",
    "        if len(dicom_vols) > 1:\n",
    "            logging.warning(\"There are more than one volume in the path, will take the largest one\")\n",
    "        input_image = dicom_vols[np.argmax([np.prod(v.GetSize()) for v in dicom_vols], axis=0)]\n",
    "    return input_image\n",
    "\n",
    "\n",
    "def postrocessing(label_image, spare=[]):\n",
    "    '''some post-processing mapping small label patches to the neighbout whith which they share the\n",
    "        largest border. All connected components smaller than min_area will be removed\n",
    "    '''\n",
    "\n",
    "    # merge small components to neighbours\n",
    "    regionmask = skimage.measure.label(label_image)\n",
    "    origlabels = np.unique(label_image)\n",
    "    origlabels_maxsub = np.zeros((max(origlabels) + 1,), dtype=np.uint32)  # will hold the largest component for a label\n",
    "    regions = skimage.measure.regionprops(regionmask, label_image)\n",
    "    regions.sort(key=lambda x: x.area)\n",
    "    regionlabels = [x.label for x in regions]\n",
    "\n",
    "    # will hold mapping from regionlabels to original labels\n",
    "    region_to_lobemap = np.zeros((len(regionlabels) + 1,), dtype=np.uint8)\n",
    "    for r in regions:\n",
    "        if r.area > origlabels_maxsub[r.max_intensity]:\n",
    "            origlabels_maxsub[r.max_intensity] = r.area\n",
    "            region_to_lobemap[r.label] = r.max_intensity\n",
    "\n",
    "    for r in tqdm(regions):\n",
    "        if r.area < origlabels_maxsub[r.max_intensity] or region_to_lobemap[r.label] in spare:\n",
    "            bb = bbox_3D(regionmask == r.label)\n",
    "            sub = regionmask[bb[0]:bb[1], bb[2]:bb[3], bb[4]:bb[5]]\n",
    "            dil = ndimage.binary_dilation(sub == r.label)\n",
    "            neighbours, counts = np.unique(sub[dil], return_counts=True)\n",
    "            mapto = r.label\n",
    "            maxmap = 0\n",
    "            myarea = 0\n",
    "            for ix, n in enumerate(neighbours):\n",
    "                if n != 0 and n != r.label and counts[ix] > maxmap:\n",
    "                    maxmap = counts[ix]\n",
    "                    mapto = n\n",
    "                    myarea = r.area\n",
    "            regionmask[regionmask == r.label] = mapto\n",
    "            if regions[regionlabels.index(mapto)].area == origlabels_maxsub[\n",
    "                regions[regionlabels.index(mapto)].max_intensity]:\n",
    "                origlabels_maxsub[regions[regionlabels.index(mapto)].max_intensity] += myarea\n",
    "            regions[regionlabels.index(mapto)].__dict__['_cache']['area'] += myarea\n",
    "\n",
    "    outmask_mapped = region_to_lobemap[regionmask]\n",
    "\n",
    "    if outmask_mapped.shape[0] == 1:\n",
    "        # holefiller = lambda x: ndimage.morphology.binary_fill_holes(x[0])[None, :, :] # This is bad for slices that show the liver\n",
    "        holefiller = lambda x: skimage.morphology.area_closing(x[0].astype(int), area_threshold=64)[None, :, :] == 1\n",
    "    else:\n",
    "        holefiller = fill_voids.fill\n",
    "\n",
    "    outmask = np.zeros(outmask_mapped.shape, dtype=np.uint8)\n",
    "    for i in np.unique(outmask_mapped)[1:]:\n",
    "        outmask[holefiller(keep_largest_connected_component(outmask_mapped == i))] = i\n",
    "\n",
    "    return outmask\n",
    "\n",
    "\n",
    "def bbox_3D(labelmap, margin=2):\n",
    "    shape = labelmap.shape\n",
    "    r = np.any(labelmap, axis=(1, 2))\n",
    "    c = np.any(labelmap, axis=(0, 2))\n",
    "    z = np.any(labelmap, axis=(0, 1))\n",
    "\n",
    "    rmin, rmax = np.where(r)[0][[0, -1]]\n",
    "    rmin -= margin if rmin >= margin else rmin\n",
    "    rmax += margin if rmax <= shape[0] - margin else rmax\n",
    "    cmin, cmax = np.where(c)[0][[0, -1]]\n",
    "    cmin -= margin if cmin >= margin else cmin\n",
    "    cmax += margin if cmax <= shape[1] - margin else cmax\n",
    "    zmin, zmax = np.where(z)[0][[0, -1]]\n",
    "    zmin -= margin if zmin >= margin else zmin\n",
    "    zmax += margin if zmax <= shape[2] - margin else zmax\n",
    "\n",
    "    return rmin, rmax, cmin, cmax, zmin, zmax\n",
    "\n",
    "\n",
    "def keep_largest_connected_component(mask):\n",
    "    mask = skimage.measure.label(mask)\n",
    "    regions = skimage.measure.regionprops(mask)\n",
    "    resizes = np.asarray([x.area for x in regions])\n",
    "    max_region = np.argsort(resizes)[-1] + 1\n",
    "    mask = mask == max_region\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5925c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7ad1ba73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def path(string):\n",
    "    if os.path.exists(string):\n",
    "        return string\n",
    "    else:\n",
    "        sys.exit(f'File not found: {string}')\n",
    "\n",
    "\n",
    "def main(path_todir_one_file, path_save_file):\n",
    "    #version = pkg_resources.require(\"lungmask\")[0].version\n",
    "    \n",
    "    #parser = argparse.ArgumentParser()\n",
    "    #parser.add_argument('input', metavar='input', type=path, help='Path to the input image, can be a folder for dicoms')\n",
    "    #parser.add_argument('output', metavar='output', type=str, help='Filepath for output lungmask')\n",
    "    #parser.add_argument('--modeltype', help='Default: unet', type=str, choices=['unet'], default='unet')\n",
    "    #parser.add_argument('--modelname', help=\"spcifies the trained model, Default: R231\", type=str, choices=['R231','LTRCLobes','LTRCLobes_R231','R231CovidWeb'], default='R231')\n",
    "    #parser.add_argument('--cpu', help=\"Force using the CPU even when a GPU is available, will override batchsize to 1\", action='store_true')\n",
    "    #parser.add_argument('--nopostprocess', help=\"Deactivates postprocessing (removal of unconnected components and hole filling\", action='store_true')\n",
    "    #parser.add_argument('--batchsize', type=int, help=\"Number of slices processed simultaneously. Lower number requires less memory but may be slower.\", default=20)\n",
    "    #parser.add_argument('--version', help=\"Shows the current version of lungmask\", action='version', version=version)\n",
    "\n",
    "    #argsin = sys.argv[1:]\n",
    "    \n",
    "    \n",
    "    #args = parser.parse_args(argsin)\n",
    "    \n",
    "    args = {\n",
    "        'input':path_todir_one_file,\n",
    "        'output':path_save_file,\n",
    "        'modeltype':'unet',#['R231','LTRCLobes','LTRCLobes_R231','R231CovidWeb'],\n",
    "        'modelname':'LTRCLobes',#['R231','LTRCLobes','LTRCLobes_R231','R231CovidWeb'],\n",
    "        #'modelpath':'./unet_r231lung1-1eab9955.pth',\n",
    "        #'modelpath':'./unet_r231-d5d2fc3d.pth',\n",
    "        'modelpath':'./unet_ltrclobes-3a07043d.pth',\n",
    "        'classes':6,\n",
    "        'cpu':True,\n",
    "        'nopostprocess':True,\n",
    "        'noHU':True,\n",
    "        'batch_size':1,\n",
    "        'version':'0.0.0.1'\n",
    "    }\n",
    "    \n",
    "    batchsize = args['batch_size']\n",
    "    if args['cpu']:\n",
    "        batchsize = 1\n",
    "\n",
    "    logging.info(f'Load model')\n",
    "    \n",
    "    input_image = get_input_image(args['input'])\n",
    "    logging.info(f'Infer lungmask')\n",
    "    if args['modelname'] == 'LTRCLobes_R231':\n",
    "        result = apply_fused(input_image)\n",
    "    else:\n",
    "        model = get_model(args['modeltype'], args['modelname'])\n",
    "        result = apply(input_image, model, force_cpu=args['cpu'], batch_size=batchsize, volume_postprocessing=not(args['nopostprocess']))\n",
    "\n",
    "    result_out= sitk.GetImageFromArray(result)\n",
    "    result_out.CopyInformation(input_image)\n",
    "    logging.info(f'Save result to: {args[\"output\"]}')\n",
    "    #sys.exit(sitk.WriteImage(result_out, args.output))\n",
    "    sys.exit(sitk.WriteImage(result_out, args['output']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9ac6c635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called as script\n",
      "INFO:root:Load model\n",
      "INFO:root:Looking for dicoms in ./Data/1/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 436.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:There are 1 volumes in the study\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Infer lungmask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Save result to: ./test.dcm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print('called as script')\n",
    "main('./Data/1/', './test.dcm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaecf76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
